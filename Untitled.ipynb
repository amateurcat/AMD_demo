{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec8db77c-e914-41f5-8e0f-82a26107e212",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "119cd4f6-38fe-4bac-a8d6-4fd212abb01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py, os,pathlib, torch, torchani, copy, threading\n",
    "from torchani.models import ANI1x \n",
    "from pathlib import Path\n",
    "#import multiprocessing as mp\n",
    "\n",
    "import torch.multiprocessing as mp\n",
    "try: # otherwise it complains: context has already been set\n",
    "    mp.set_start_method(\"spawn\")\n",
    "except: \n",
    "    pass\n",
    "\n",
    "#import threading, queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7817210b-982c-4dab-b44a-a8ee036b17d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import *\n",
    "from sampler import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95576c39-9ed8-4a4c-bdbe-1fe5d94ffee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py, os, sys, re, pathlib, torch, torchani, random, subprocess\n",
    "import threading, queue\n",
    "\n",
    "from ase import Atoms, units\n",
    "from ase.md.langevin import Langevin\n",
    "from pathlib import Path\n",
    "\n",
    "from utils import *\n",
    "\n",
    "from multiprocessing import Pool, Manager\n",
    "from multiprocessing import set_start_method\n",
    "try:\n",
    "    set_start_method('spawn')\n",
    "except RuntimeError:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "#MD settings\n",
    "MD_MAXSTEPS = 100   #DEBUG: larger upper bound\n",
    "MD_STEPLENGTH = 0.5 * units.fs\n",
    "CHECK_INTERVAL = 5\n",
    "#TODO: there is no need to hard code this species order, should be possible to use the dict in the model with extra transformation\n",
    "SPECIES_ORDER=('H', 'C', 'N', 'O', 'F', 'S', 'Cl')   \n",
    "QBC_CUTOFF = 0.0002   #DEBUG: change it to a reasonable value, for demo purpose use small value to ensure MD triggered in the first step\n",
    "\n",
    "TMP='/dev/shm'\n",
    "DELETE_TMP=True\n",
    "\n",
    "ORCA_PATH = Path('/storage/users/roman/Apps/orca_5_0_1_linux_x86-64_shared_openmpi411')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eed3e27-c023-4360-a41d-90e2d9698203",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooldir = Path('/home/shuhao/AMD_demo/pool')\n",
    "\n",
    "MAX_AL_EPOCH = 2\n",
    "\n",
    "gpu_list = [\"cuda:1\"]\n",
    "#gpu_list = [\"cpu\"]\n",
    "\n",
    "model = torchani.models.ANI1x().to(gpu_list[0])\n",
    "#we will train on relative energy, so disable the energy_shifter in the model\n",
    "model.energy_shifter.self_energies = torch.tensor([ 0.0, 0.0, 0.0, 0.0]).double().to(gpu_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc1ea052-bcb8-4599-b480-6e39dc535f04",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = gpu_list[0]\n",
    "Rcr = 5.2000e+00\n",
    "Rca = 3.5000e+00\n",
    "EtaR = torch.tensor([1.6000000e+01], device=device)\n",
    "ShfR = torch.tensor([9.0000000e-01, 1.1687500e+00, 1.4375000e+00, 1.7062500e+00, 1.9750000e+00, 2.2437500e+00, 2.5125000e+00, 2.7812500e+00, 3.0500000e+00, 3.3187500e+00, 3.5875000e+00, 3.8562500e+00, 4.1250000e+00, 4.3937500e+00, 4.6625000e+00, 4.9312500e+00], device=device)\n",
    "Zeta = torch.tensor([3.2000000e+01], device=device)\n",
    "ShfZ = torch.tensor([1.9634954e-01, 5.8904862e-01, 9.8174770e-01, 1.3744468e+00, 1.7671459e+00, 2.1598449e+00, 2.5525440e+00, 2.9452431e+00], device=device)\n",
    "EtaA = torch.tensor([8.0000000e+00], device=device)\n",
    "ShfA = torch.tensor([9.0000000e-01, 1.5500000e+00, 2.2000000e+00, 2.8500000e+00], device=device)\n",
    "species_order = ['H', 'C', 'N', 'O','F','S','Cl']\n",
    "num_species = len(species_order)\n",
    "aev_computer = torchani.AEVComputer(Rcr, Rca, EtaR, ShfR, EtaA, Zeta, ShfA, ShfZ, num_species, use_cuda_extension=False)\n",
    "\n",
    "model.aev_computer = aev_computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c841a46f-c187-40df-9103-a885aa6a7d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor(h5file, MD_queue):\n",
    "    print('extarcting')\n",
    "    db = h5py.File(h5file,'r')\n",
    "    for key in list(db.keys())[:1]:\n",
    "        species = np.array(db[key]['species']).copy()\n",
    "        #Due to some problem in previous vrsion of h5py\n",
    "        #Species array in ani1x dataset is not purely str and need a transformation here\n",
    "        #species = np.array(db[key]['species']).astype(str).copy()\n",
    "        for c in db[key]['coordinates'][:2]:\n",
    "            coordinates = np.array(c).copy()\n",
    "            MD_queue.put((key, species, coordinates))\n",
    "\n",
    "    db.close()   #DEBUG: this should be enabled if you want to write to existing files\n",
    "    \n",
    "    \n",
    "def MD_sampler(model, MD_queue, QM_queue):\n",
    "    #while MD_queue.qsize()>0:\n",
    "    while True:\n",
    "        print('running MD')\n",
    "        #species and coordinates in the input are in the same format as in h5 file\n",
    "        key, species, coordinates = MD_queue.get()\n",
    "        device = list(model.neural_networks[0].parameters())[0].device\n",
    "        \n",
    "        species = np.array(species).astype(str)\n",
    "        atoms = Atoms(convert_char_list(species), positions=coordinates)\n",
    "\n",
    "        idx = {k: i for i, k in enumerate(SPECIES_ORDER)}\n",
    "        s = np.array([idx[s] for s in species], dtype='i8')\n",
    "        s = torch.tensor([s]).to(device)\n",
    "        \n",
    "        temp = random.randint(50,800) * units.kB\n",
    "        calculator = model.ase()\n",
    "        atoms.set_calculator(calculator)\n",
    "        dyn = Langevin(atoms, MD_STEPLENGTH, temperature_K=temp, friction=0.02)\n",
    "\n",
    "        steps = 0\n",
    "        sampled = False\n",
    "        while steps <= MD_MAXSTEPS:\n",
    "            dyn.run(CHECK_INTERVAL)\n",
    "            c = atoms.get_positions()\n",
    "            c = torch.tensor([c]).float().to(device)\n",
    "            _,_,qbc = model.energies_qbcs((s,c))\n",
    "            if float(qbc) > QBC_CUTOFF:\n",
    "                sampled = True\n",
    "                break\n",
    "            else:\n",
    "                steps += CHECK_INTERVAL\n",
    "                \n",
    "        if sampled:  \n",
    "            QM_queue.put((key, species, atoms.get_positions().copy()))\n",
    "        else:\n",
    "            pass\n",
    "        MD_queue.task_done()\n",
    "        print('MD finished')\n",
    "\n",
    "def QM_runner(QM_queue, collector):\n",
    "    \n",
    "    while True:\n",
    "        print('running QM')\n",
    "        key, species, coordinates = QM_queue.get()\n",
    "        with in_tempdir(basedir=TMP, delete_temp=DELETE_TMP):\n",
    "            write_smear_input(species, coordinates, '1.inp')\n",
    "            result = subprocess.run('export LD_LIBRARY_PATH=\"%s:$LD_LIBRARY_PATH\"&&%s %s.inp > %s.out'%(ORCA_PATH, ORCA_PATH/'orca', 1, 1), shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            output_file = str(1)+'.out'\n",
    "            energy = get_energy(output_file)   #sometimes DFT would fail and get_energy returns np.nan\n",
    "        colector.append((key, species, coordinates, energy))\n",
    "        QM_queue.task_done()\n",
    "        print('QM finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b140025-7900-4b73-aa3d-a9221d02826c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extarcting\n",
      "running MD\n",
      "MD finished\n",
      "running MD\n",
      "MD finished\n",
      "running MD\n"
     ]
    }
   ],
   "source": [
    "MD_queue = queue.Queue()\n",
    "QM_queue =queue.Queue()\n",
    "#MD_queue.start()\n",
    "#QM_queue.start()\n",
    "MD_queue.join()\n",
    "QM_queue.join()\n",
    "cl = mp.Manager()\n",
    "collector = cl.list()\n",
    "\n",
    "extract_server = threading.Thread(target=extractor('pool/ANI-1x_wb97x_dz_testcase_2.h5',MD_queue), daemon=True)\n",
    "MD_server = threading.Thread(target=MD_sampler(model=model, MD_queue=MD_queue, QM_queue=QM_queue), daemon=True)\n",
    "QM_server = threading.Thread(target=QM_runner(QM_queue, collector), daemon=True)\n",
    "\n",
    "extract_server.start()\n",
    "MD_server.start()\n",
    "QM_server.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c2b1de4-0bfe-4235-8f11-e4cb2c2fb3e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tried to serialize object __torch__.torch.classes.cuaev.CuaevComputer which does not have a __getstate__ method defined!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/user/1508/ipykernel_601503/2540157311.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mMD_server\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mQM_server\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/softwares/miniconda3/envs/autoani/lib/python3.8/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/softwares/miniconda3/envs/autoani/lib/python3.8/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/softwares/miniconda3/envs/autoani/lib/python3.8/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_spawn_posix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mForkServerProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/softwares/miniconda3/envs/autoani/lib/python3.8/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/softwares/miniconda3/envs/autoani/lib/python3.8/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/softwares/miniconda3/envs/autoani/lib/python3.8/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mset_spawning_popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/softwares/miniconda3/envs/autoani/lib/python3.8/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mForkingPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tried to serialize object __torch__.torch.classes.cuaev.CuaevComputer which does not have a __getstate__ method defined!"
     ]
    }
   ],
   "source": [
    "MD_queue = mp.JoinableQueue()\n",
    "QM_queue = mp.JoinableQueue()\n",
    "\n",
    "MD_queue.join()\n",
    "QM_queue.join()\n",
    "\n",
    "cl = mp.Manager()\n",
    "collector = cl.list()\n",
    "\n",
    "data_server = mp.Process(target=extractor, args=('pool/ANI-1x_wb97x_dz_testcase_2.h5', MD_queue))\n",
    "MD_server =  mp.Process(target=MD_sampler, args=(model, 'pool/ANI-1x_wb97x_dz_testcase_2.h5', QM_queue))\n",
    "QM_server =  mp.Process(target=QM_runner, args=(QM_queue, collector))\n",
    "\n",
    "\n",
    "MD_server.start()\n",
    "QM_server.start()\n",
    "\n",
    "data_server.start()\n",
    "data_server.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee79e6e6-583a-442d-93c6-ff3388d28924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
